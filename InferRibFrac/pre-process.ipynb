{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import ndimage\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import disk, remove_small_objects\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset.fracnet_dataset import FracNetInferenceDataset\n",
    "from dataset import transforms as tsfm\n",
    "from model.unet import UNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \".\\\\data\\\\RibFrac501-image.nii.gz\"\n",
    "\n",
    "transforms = [\n",
    "    tsfm.Window(-200, 1000),\n",
    "    tsfm.MinMaxNorm(-200, 500)\n",
    "]\n",
    "batch_size = 16\n",
    "num_workers = 4\n",
    "\n",
    "# model = UNet(1, 1, first_out_channels=16)\n",
    "# model.eval()\n",
    "# model_weights = torch.load(\"model_weights.pth\")\n",
    "# model.load_state_dict(model_weights)\n",
    "# model = nn.DataParallel(model).cuda()\n",
    "\n",
    "dataset = FracNetInferenceDataset(image_path, transforms=transforms)\n",
    "dataloader = FracNetInferenceDataset.get_dataloader(dataset,\n",
    "    batch_size, num_workers)\n",
    "pred = np.zeros(dataloader.dataset.image.shape)\n",
    "crop_size = dataloader.dataset.crop_size\n",
    "with torch.no_grad():\n",
    "    for _,sample in enumerate(dataloader):\n",
    "        images, centers = sample\n",
    "        # images = images.cuda()\n",
    "        # output = model(images).sigmoid().cpu().numpy().squeeze(axis=1)\n",
    "        images = images.numpy().squeeze(axis=1)\n",
    "        # print(\"images:\",images.shape)\n",
    "        # print(\"\")\n",
    "\n",
    "        for i in range(len(centers)):\n",
    "            center_x, center_y, center_z = centers[i]\n",
    "            cur_pred_patch = pred[\n",
    "                center_x - crop_size // 2:center_x + crop_size // 2,\n",
    "                center_y - crop_size // 2:center_y + crop_size // 2,\n",
    "                center_z - crop_size // 2:center_z + crop_size // 2\n",
    "            ]\n",
    "            pred[\n",
    "                center_x - crop_size // 2:center_x + crop_size // 2,\n",
    "                center_y - crop_size // 2:center_y + crop_size // 2,\n",
    "                center_z - crop_size // 2:center_z + crop_size // 2\n",
    "            ] = np.where(cur_pred_patch > 0, np.mean((images[i],\n",
    "                cur_pred_patch), axis=0), images[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import skimage\n",
    "lmage_array = sitk.GetImageFromArray(pred.astype('int8'))\n",
    "# closed = sitk.BinaryMorphologicalClosing(lmage_array,15,sitk.sitkBall)\n",
    "dilated = sitk.BinaryDilate(lmage_array, (3,1,1), sitk.sitkBall)\n",
    "# Eroded = sitk.BinaryErode(dilated,3,sitk.sitkBall)\n",
    "# holesfilled = sitk.BinaryFillhole(Eroded,fullyConnected=True)\n",
    "# bmopening = sitk.BinaryMorphologicalOpening(lmage_array,3,sitk.sitkBall)\n",
    "im = sitk.GetArrayFromImage(dilated)\n",
    "# im = holesfilled\n",
    "# res = np.multiply(pred, holesfilled)\n",
    "# res1 = skimage.measure.label(res, connectivity=1)\n",
    "# rib_p = skimage.measure.regionprops(res1)\n",
    "# rib_p.sort(key=lambda x: x.area, reverse=True)\n",
    "# im = np.in1d(res1, [x.label for x in rib_p[:24]]).reshape(res1.shape)\n",
    "# im = im.astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_image = nib.Nifti1Image(pred, dataset.image_affine)\n",
    "# pred_image = nib.Nifti1Image(im, dataset.image_affine)\n",
    "save_path = \".\\\\data\\\\tmp\"\n",
    "nib.save(pred_image,save_path+\"\\RibFrac501-pred-test2.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    tsfm.Window(-200, 1000),\n",
    "    tsfm.MinMaxNorm(-200, 1000)\n",
    "]\n",
    "\n",
    "dataset = FracNetInferenceDataset(image_path, transforms=transforms)\n",
    "dataloader = FracNetInferenceDataset.get_dataloader(dataset,\n",
    "    batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from dataset import transforms as tsfm\n",
    "image = nib.load(\".\\data\\RibFrac501-image.nii.gz\")\n",
    "image_affine = image.affine\n",
    "image = image.get_fdata().astype(np.int16)\n",
    "crop_size=64\n",
    "\n",
    "dim_coords = [list(range(0, dim, crop_size // 2))[1:-1]\\\n",
    "            + [dim - crop_size // 2] for dim in image.shape]\n",
    "centers = list(product(*dim_coords))\n",
    "\n",
    "transforms = [\n",
    "    tsfm.Window(-200, 1000),\n",
    "    tsfm.MinMaxNorm(-200, 1000)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8556c49052b5cabb9d2c490e92acb124b73214d24c22c0b13c0fd41c83b56bfe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('zlylab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
